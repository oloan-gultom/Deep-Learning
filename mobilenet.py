# -*- coding: utf-8 -*-
"""MobileNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hDZu5ILVyoaCRLcUE-Y2JnwEWstSqkiy
"""

from google.colab import drive
import os
drive.mount('/content/gdrive')

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dropout
from keras.models import Sequential
from keras.layers import Dense, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.applications.mobilenet import MobileNet

import os
base_dir = '/content/gdrive/My Drive/dataset/'
label = os.listdir(base_dir)
label

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    width_shift_range=0.2,
                    height_shift_range=0.2,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'wrap',
                    validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
        base_dir,
        target_size=(150, 150),
        batch_size= 32,
        #class_mode='sparse',
        shuffle=True,
        subset='training')

validation_generator = train_datagen.flow_from_directory(
        base_dir,
        target_size=(150, 150),
        batch_size= 32,
        #class_mode='sparse',
        subset='validation')

model = MobileNet(include_top = False,
                          weights = 'imagenet',
                          input_shape = (150,150,3))
model.summary()

for layer in model.layers:
  if layer.name == 'conv_pw_3':
    break
  layer.trainable = False
  print('Layer' + layer.name + 'frozen.')
model.summary()

from keras.layers import BatchNormalization
# from keras.regularizers import l1, l2
from keras import Model

inp = model.input
m = model.output
m = Flatten()(m)
m = Dense(32, activation='relu')(m)
m = BatchNormalization()(m)
m = Dropout(0.1)(m)
predict = Dense(4, activation='softmax')(m)

model_new = Model(inputs=model.input, outputs=predict)
model_new.summary()

from keras.optimizers import adam

opt = adam.Adam(0.0001, beta_1=0.9, beta_2=0.999, amsgrad=True)
model_new.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

history = model_new.fit(
      train_generator,
      validation_data=validation_generator,
      epochs=10,
      steps_per_epoch=len(train_generator),
      validation_steps=len(validation_generator),
      verbose=2)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
# import matplotslib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator
# %matplotlib inline

# plot the loss
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.show()
# plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
# plt.savefig('AccVal_acc')

model_new.save('/content/gdrive/My Drive/Skripsi/model/Mobile.h5')

# load trained model
model = load_model('/content/gdrive/My Drive/Skripsi/model/Mobile.h5')
# define test data generator with rescaling only
test_datagen = ImageDataGenerator(rescale=1./255)

# load test data
test_data = test_datagen.flow_from_directory(
    '/content/gdrive/My Drive/Skripsi/Corn/tes/',
    target_size=(150, 150), # set image size as same as training data
    batch_size=32,
    class_mode='categorical')

# evaluate model on test data
test_accuracy = model.evaluate(test_data)
print('Test Accuracy:', test_accuracy)

from sklearn.metrics import confusion_matrix
import numpy as np
import seaborn as sns

# load the model

model = load_model('/content/gdrive/My Drive/Skripsi/model/Mobile.h5')

label_names = list(test_data.class_indices.keys())

# define test data generator with rescaling only
test_datagen = ImageDataGenerator(rescale=1./255)

# load test data
test_data = test_datagen.flow_from_directory(
    '/content/gdrive/My Drive/Skripsi/Corn/tes/',
    target_size=(150, 150), # set image size as same as training data
    batch_size=32,
    shuffle= False,
    class_mode='categorical')

# make predictions on test data
test_predictions = model.predict(test_data)

# convert predictions from one-hot encoding to class labels
test_labels = np.argmax(test_predictions, axis=1)

# get true labels of test data
true_labels = test_data.classes

# compute confusion matrix
cm = confusion_matrix(true_labels, test_labels)

# display confusion matrix
print('Confusion Matrix:')
print(cm)


sns.heatmap(cm ,annot=True, cmap= "Blues", fmt="d", square=True,
            xticklabels=label_names, yticklabels=label_names)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# compute overall accuracy
accuracy = accuracy_score(true_labels, test_labels)
print('Accuracy:', accuracy)

# compute precision, recall, and F1-score for each class
precision = precision_score(true_labels, test_labels, average=None)
recall = recall_score(true_labels, test_labels, average=None)
f1 = f1_score(true_labels, test_labels, average=None)

# display metrics for each class
for i in range(len(precision)):
    print('Class', i+1, 'Precision:', precision[i])
    print('Class', i+1, 'Recall:', recall[i])
    print('Class', i+1, 'F1-score:', f1[i])



uploaded = files.upload()
import tensorflow as tf
import numpy as np
for fn in uploaded.keys():

  # predicting images
  path = fn
  img = tf.keras.utils.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = tf.keras.utils.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  label = train_generator.class_indices
  label = list(label.keys())
  for i in range(len(classes[0])) :
    print(i ,label[i], ":", round(classes[0][i])*100,"%")

from keras.utils.generic_utils import to_list
label = train_generator.class_indices
label = list(label.keys())
label